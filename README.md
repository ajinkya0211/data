# üîπ AI-Integrated Smart Python Notebook System

A deep AI integrated smart Python notebook system with a slick UI that combines the power of Jupyter notebooks with AI assistance, visual DAG workflows, and professional data science tooling.

## üöÄ **NEW: Multi-AI Provider Support!**

**Default: Ollama (Local)** - Run AI models locally for privacy and speed
**Plus: OpenAI & Gemini** - Cloud AI when you need more power

- ü§ñ **Ollama (Local)**: Fast, private, no API costs
- üåê **OpenAI GPT-4**: Enterprise-grade AI capabilities  
- üîÆ **Google Gemini**: Advanced reasoning and analysis
- üîÑ **Automatic Fallback**: Seamless provider switching

## üèóÔ∏è Architecture Overview

```
[ Web App (React) ]
     ‚îÇ  ‚îú‚îÄ REST/WS
     ‚ñº
[API Gateway (FastAPI)] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ                                                                           ‚îÇ
     ‚îú‚îÄ‚îÄ Project/Parser Service  ‚îÄ‚îÄ‚îê                                             ‚îÇ
     ‚îÇ     (blocks+DAG+versions)   ‚îÇ  emits events   ‚îå‚îÄ> [Redis/Queue] ‚îÄ‚îÄ> Executor
     ‚îÇ                             ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ
     ‚îú‚îÄ‚îÄ Data Catalog Service  <‚îÄ‚îÄ‚îÄ‚î§  profiles/update                             ‚îÇ
     ‚îÇ     (datasets+profiles)     ‚îÇ                                             ‚îÇ
     ‚îú‚îÄ‚îÄ Execution Service (Kernels+Scheduler+Artifacts) ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
     ‚îÇ     (jupyter_client / kernels)                           ‚îÇ WS events     ‚îÇ
     ‚îú‚îÄ‚îÄ LLM Orchestrator (Multi-Provider) ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
     ‚îÇ     (Ollama + OpenAI + Gemini)                                           ‚îÇ
     ‚îú‚îÄ‚îÄ Auth/RBAC Service                                                        ‚îÇ
     ‚îÇ                                                                           ‚îÇ
     ‚îú‚îÄ‚îÄ Realtime/Event Hub  (WebSocket)                                          ‚îÇ
     ‚îÇ                                                                           ‚îÇ
     ‚îú‚îÄ‚îÄ Postgres (metadata)     ‚îÄ‚îÄ> versioned state                              ‚îÇ
     ‚îú‚îÄ‚îÄ S3/MinIO (artifacts)    ‚îÄ‚îÄ> outputs, html, images, parquet               ‚îÇ
     ‚îî‚îÄ‚îÄ Redis (cache/queue)     ‚îÄ‚îÄ> runs, plans, locks                           
```

## üöÄ Features

- **ü§ñ Multi-AI Provider Support**: Ollama (local), OpenAI, Gemini
- **AI-Powered Workflows**: Natural language to code blocks via LLM orchestration
- **Visual DAG Editor**: ReactFlow-based canvas for building data pipelines
- **Smart Data Profiling**: Automatic dataset understanding and metadata extraction
- **Incremental Execution**: Only run affected blocks when dependencies change
- **Real-time Collaboration**: WebSocket-based live updates and collaboration
- **Professional Export**: Notebook, script, and report generation
- **Version Control**: Complete project history with diff views

## üõ†Ô∏è Tech Stack

### Backend
- **FastAPI**: Modern Python web framework
- **PostgreSQL**: Primary database for metadata
- **Redis**: Caching, queues, and WebSocket pub/sub
- **Jupyter Client**: Python kernel execution
- **Pydantic**: Data validation and serialization
- **Celery**: Background task processing

### AI & ML Providers
- **Ollama**: Local AI models (llama3.2, codellama, mistral)
- **OpenAI**: GPT-4 and GPT-3.5 models
- **Google Gemini**: Advanced reasoning models
- **LangChain**: AI agent framework integration

### Frontend
- **React 18**: Modern React with hooks
- **TypeScript**: Type-safe development
- **ReactFlow**: DAG visualization and editing
- **Monaco Editor**: Code editing with language support
- **Tailwind CSS**: Utility-first CSS framework
- **React Query**: Server state management

## üöÄ Quick Start

### Prerequisites
- Docker and Docker Compose
- Python 3.11+
- Node.js 18+

### Development Setup

1. **Clone and setup**
```bash
git clone <repository>
cd ai-notebook-system

# Run the automated setup script
./setup.sh
```

2. **Access your system**
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs
- Ollama API: http://localhost:11434

## ü§ñ AI Provider Configuration

### Ollama (Default - Local)
```bash
# Ollama runs locally with Docker
# Default model: llama3.2:3b
# Available models: llama3.2, codellama, mistral, neural-chat

# Download additional models
ollama pull codellama:7b
ollama pull mistral:7b

# Check available models
curl http://localhost:11434/api/tags
```

### OpenAI
```bash
# Add to .env file
OPENAI_API_KEY=your_openai_api_key_here
DEFAULT_AI_PROVIDER=openai  # Optional: change default
```

### Google Gemini
```bash
# Add to .env file
GEMINI_API_KEY=your_gemini_api_key_here
DEFAULT_AI_PROVIDER=gemini  # Optional: change default
```

### Provider Switching
```python
# In your AI requests, specify provider
response = await ai_provider_service.generate_response(
    prompt="Your prompt here",
    provider=AIProvider.OPENAI  # or OLLAMA, GEMINI
)
```

## üìä Sample Workflow

1. **Create Project**: Start a new "Sales Analysis" project
2. **Import Data**: Upload `data_dirty.csv` - automatic profiling
3. **AI Chat**: "Show me total sales by category with a bar chart"
4. **AI Response**: Uses Ollama (local) by default, or specify provider
5. **Visual DAG**: See the generated blocks and their dependencies
6. **Execute**: Run the pipeline and view results
7. **Export**: Generate notebook or report

## üîß Configuration

### Environment Variables
```bash
# AI Provider Configuration
DEFAULT_AI_PROVIDER=ollama  # ollama, openai, gemini

# Ollama (Local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_DEFAULT_MODEL=llama3.2:3b

# OpenAI
OPENAI_API_KEY=your_openai_key
OPENAI_MODEL=gpt-4.1-mini

# Gemini
GEMINI_API_KEY=your_gemini_key
GEMINI_MODEL=gemini-1.5-pro

# Other services
DATABASE_URL=postgresql://user:pass@localhost/notebooks
REDIS_URL=redis://localhost:6379
JWT_SECRET=your_jwt_secret
```

## üåü AI Features

### Code Generation
- Natural language to Python code
- Data science specific prompts
- Error analysis and fixes
- Code explanation and optimization

### Workflow Assistance
- DAG optimization suggestions
- Performance recommendations
- Best practices guidance
- Alternative approach suggestions

### Multi-Provider Benefits
- **Ollama**: Fast, private, no API costs
- **OpenAI**: High-quality, enterprise features
- **Gemini**: Advanced reasoning, cost-effective
- **Fallback**: Automatic provider switching

## üìà Roadmap

### Phase 1: POC (Current)
- [x] Multi-AI provider support
- [x] Ollama local integration
- [x] OpenAI and Gemini support
- [x] Basic FastAPI backend
- [x] React frontend with DAG canvas
- [x] Data profiling service
- [ ] LLM orchestration
- [ ] Execution service

### Phase 2: MVP
- [ ] Advanced AI workflows
- [ ] Model fine-tuning
- [ ] Custom prompt templates
- [ ] AI performance analytics

## üß™ Testing

```bash
# Backend tests
cd backend
pytest

# Frontend tests
cd frontend
npm test

# AI provider tests
curl http://localhost:8000/api/v1/ai/health
```

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## üìÑ License

MIT License - see LICENSE file for details

## üÜò Support

- Create an issue for bugs or feature requests
- Check the documentation in `/docs`
- Join our community discussions

---

‚ö° **Ready to build the future of AI-powered data science? Your multi-provider AI notebook system is ready! üöÄ** 